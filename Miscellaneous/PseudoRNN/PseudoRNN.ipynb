{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PseudoRNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesPeralta/Machine-Learning-Algorithms/blob/master/Miscellaneous/PseudoRNN/PseudoRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KIscKFhFWEmU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Understanding Recurrent neural networks\n",
        "* A major characteristic of all neural networks i've seen so far, such as densely connected networks and covnets, is that they have no memory.\n",
        "* Each input shown to them is processed independently, with no state kept in between inputs\n",
        "* But in real life, our bilogical intelligience processes information incrementally while maintaining an internal model of what it's processing, built from past information and constantly updates as new information comes in\n",
        "* An **RNN** it processes sequences by iterating through the sequence elements and maintaining a state containing information relative to what it's seen so far. In effect, an RNN is a type of neural network that has an internal loop\n",
        "* The state of the RNN is reset between processing two different, independent sequences\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sLI-9uIbZkGz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Loop and state clarification\n",
        "* input is a sequence of vectors as (timesteps, input_features)\n",
        "* It will loop over the timesteps\n",
        "* At each timestep, it considers its current state at t and the input at t (of shape (input_features,))\n"
      ]
    },
    {
      "metadata": {
        "id": "u1Ev-y6Jancm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Naive Numpy implementation of the forward pass of the simple RNN"
      ]
    },
    {
      "metadata": {
        "id": "bSEWJ4m_asrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ae0885f-38e4-4548-f0a2-34d577b5faac"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 100\n",
        "input_features = 32\n",
        "output_features = 64\n",
        "  \n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "state_t = np.zeros((output_features,))\n",
        "     \n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "                   \n",
        "successive_outputs = []\n",
        "for input_t in inputs:\n",
        "  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "  successive_outputs.append(output_t)\n",
        "  state_t = output_t\n",
        "\n",
        "final_output_sequence = np.concatenate(successive_outputs, axis=0)\n",
        "\n",
        "print(final_output_sequence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.99999999 0.99999998 1.         ... 1.         1.         1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}