{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing_DeepDream.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesPeralta/Machine-Learning-Algorithms/blob/master/Generative%20Models/DeepDream/Implementing_DeepDream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kfC8UG4I3ifd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementing DeepDream in Keras"
      ]
    },
    {
      "metadata": {
        "id": "XgU4H0JH5fc_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start from a convnet pretrained on ImageNet\n",
        "### VGG16, VGG19, Xception, ResNet50, etc. can implement DeepDream, but your convnet of choice will naturally affect your visualizations, because different convnet architectures result in different learned features."
      ]
    },
    {
      "metadata": {
        "id": "KV-uC5KH3lnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import inception_v3\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQy45YHiCbmM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpGOnWZBCf2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e57f9c9f-c180-4b66-ca94-77757df229af"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "picture_location = '/content/drive/My Drive/Datasets/DeepDream/Brian'\n",
        "\n",
        "os.chdir(picture_location)\n",
        "os.listdir()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Brian.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "xlL62Uyh4QLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.set_learning_phase(0)\n",
        "\n",
        "# For our example we will be using the Inception V3 network\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9Y6Tya05HTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compute the loss\n",
        "### The quantity you’ll seek to maximize during the gradient-ascent process. For filter visulization, I maximized the value of a specific filter in a specific layer. Here, ill simultaneously maximize the activation of all filters in a number of layers. \n",
        "### Specifically, you’ll maximize a weighted sum of the L2 norm of the activations of a set of high-level layers. The exact set of layers you choose (as well as their contribution to the final loss) has a major influence on the visuals you’ll be able to produce, so you want to make these parameters easily configurable."
      ]
    },
    {
      "metadata": {
        "id": "Fjbz6uaA5Hpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11305
        },
        "outputId": "683f27f4-78c7-46e1-ef27-12b930450505"
      },
      "cell_type": "code",
      "source": [
        "# Setting up the DeepDream configuration\n",
        "layer_contributions = {\n",
        "    'mixed7': 0.2,    # Dictionary mapping layer names to a coefficient quantifying\n",
        "    'mixed8': 3.,     # how much the layer’s activation contributes to the loss  \n",
        "    'mixed9': 2.,     # you’ll seek to maximize. Note that the layer names are\n",
        "    'mixed10': 1.5,    # hardcoded in the built-in Inception V3 application. You can\n",
        "}                     # list all layer names using model.summary().\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, None, None, 3 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, None, None, 3 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, None, None, 3 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, None, None, 3 9216        activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, None, None, 3 96          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, None, None, 3 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, None, None, 6 18432       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, None, None, 6 192         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, None, None, 6 0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, None, None, 8 5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, None, None, 8 240         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, None, None, 8 0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, None, None, 1 138240      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, None, None, 6 192         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, None, None, 6 0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, None, None, 9 55296       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, None, None, 4 144         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, None, None, 9 288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, None, None, 4 0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, None, None, 9 0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, None, None, 1 0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, None, None, 6 76800       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, None, None, 9 82944       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, None, None, 6 192         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, None, None, 6 192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, None, None, 9 288         conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, None, None, 3 96          conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, None, None, 6 0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, None, None, 6 0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, None, None, 9 0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, None, None, 3 0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_100[0][0]             \n",
            "                                                                 activation_102[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "                                                                 activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, None, None, 6 192         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, None, None, 6 0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, None, None, 9 55296       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, None, None, 4 144         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, None, None, 9 288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, None, None, 4 0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, None, None, 9 0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, None, None, 6 76800       activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, None, None, 9 82944       activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, None, None, 6 192         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, None, None, 6 192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, None, None, 9 288         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, None, None, 6 192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, None, None, 6 0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, None, None, 6 0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, None, None, 9 0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, None, None, 6 0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_107[0][0]             \n",
            "                                                                 activation_109[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, None, None, 6 192         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, None, None, 6 0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, None, None, 9 55296       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, None, None, 4 144         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, None, None, 9 288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, None, None, 4 0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, None, None, 9 0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, None, None, 6 76800       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, None, None, 9 82944       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, None, None, 6 192         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, None, None, 6 192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, None, None, 9 288         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, None, None, 6 192         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, None, None, 6 0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, None, None, 6 0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, None, None, 9 0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, None, None, 6 0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_114[0][0]             \n",
            "                                                                 activation_116[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "                                                                 activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, None, None, 6 192         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, None, None, 6 0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, None, None, 9 55296       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, None, None, 9 288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, None, None, 9 0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, None, None, 9 82944       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, None, None, 3 1152        conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, None, None, 9 288         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, None, None, 3 0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, None, None, 9 0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_121[0][0]             \n",
            "                                                                 activation_124[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, None, None, 1 114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, None, None, 1 114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, None, None, 1 384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, None, None, 1 114688      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, None, None, 1 114688      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, None, None, 1 384         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, None, None, 1 384         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, None, None, 1 172032      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, None, None, 1 172032      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, None, None, 1 576         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, None, None, 1 576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_125[0][0]             \n",
            "                                                                 activation_128[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, None, None, 1 179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, None, None, 1 480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, None, None, 1 179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, None, None, 1 480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, None, None, 1 480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, None, None, 1 179200      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, None, None, 1 179200      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, None, None, 1 480         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, None, None, 1 215040      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, None, None, 1 576         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_135[0][0]             \n",
            "                                                                 activation_138[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, None, None, 1 480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, None, None, 1 179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, None, None, 1 179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, None, None, 1 179200      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, None, None, 1 179200      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, None, None, 1 480         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, None, None, 1 480         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, None, None, 1 215040      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, None, None, 1 215040      activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, None, None, 1 576         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, None, None, 1 576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_145[0][0]             \n",
            "                                                                 activation_148[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, None, None, 1 576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, None, None, 1 0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, None, None, 1 258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, None, None, 1 576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, None, None, 1 0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, None, None, 1 258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, None, None, 1 576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, None, None, 1 0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, None, None, 1 258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, None, None, 1 258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, None, None, 1 576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, None, None, 1 576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, None, None, 1 0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, None, None, 1 0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, None, None, 1 258048      activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, None, None, 1 258048      activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, None, None, 1 576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, None, None, 1 0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_155[0][0]             \n",
            "                                                                 activation_158[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "                                                                 activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, None, None, 1 258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, None, None, 1 258048      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, None, None, 1 576         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, None, None, 1 0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, None, None, 3 552960      activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, None, None, 1 331776      activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, None, None, 3 960         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, None, None, 1 576         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, None, None, 3 0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, None, None, 1 0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_166[0][0]             \n",
            "                                                                 activation_170[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, None, None, 4 1344        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, None, None, 4 0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, None, None, 3 1548288     activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, None, None, 3 1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, None, None, 3 1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, None, None, 3 0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, None, None, 3 0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, None, None, 3 1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, None, None, 3 1152        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, None, None, 3 1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, None, None, 3 1152        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, None, None, 3 960         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, None, None, 3 0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, None, None, 3 0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, None, None, 3 0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, None, None, 3 0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, None, None, 3 0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_173[0][0]             \n",
            "                                                                 activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, None, 7 0           activation_177[0][0]             \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_171[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, None, None, 4 1344        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, None, None, 4 0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, None, None, 3 1548288     activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, None, None, 3 1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, None, None, 3 1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, None, None, 3 0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, None, None, 3 0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, None, None, 3 1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, None, None, 3 1152        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, None, None, 3 1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, None, None, 3 1152        conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, None, None, 3 960         conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, None, None, 3 0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, None, None, 3 0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, None, None, 3 0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, None, None, 3 0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, None, None, 3 0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_182[0][0]             \n",
            "                                                                 activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, None, None, 7 0           activation_186[0][0]             \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_180[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_188[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FG_fQ9pC659s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "832e636a-6400-47b3-bc1d-5d9fda6a7189"
      },
      "cell_type": "code",
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers]) # Creates a dictionary that maps layer names to layer instances\n",
        "\n",
        "loss = K.variable(0.) # Define the loss by adding layer contribution to this scalar variable\n",
        "\n",
        "for layer_name in layer_contributions:\n",
        "  coeff = layer_contributions[layer_name]\n",
        "  activation = layer_dict[layer_name].output # Retrieves the layer's output array\n",
        "  scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "  loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7sr-lBd07gfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dream = model.input # This tensor holds the dream\n",
        "\n",
        "grads = K.gradients(loss, dream)[0] # Computes the gradients (important trick)\n",
        "\n",
        "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
        "\n",
        "outputs = [loss, grads]                              # Sets up a Keras function to retrieve the value of \n",
        "fetch_loss_and_grads = K.function([dream], outputs)  # the loss and gradients, given an input image\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "  outs = fetch_loss_and_grads([x])\n",
        "  loss_value = outs[0]\n",
        "  grad_values = outs[1]\n",
        "  return loss_value, grad_values\n",
        "\n",
        "# This function runs gradient ascent for a number of iterations.\n",
        "def gradient_ascent(x, iterations, step, max_loss=None): \n",
        "  for i in range(iterations):\n",
        "     loss_value, grad_values = eval_loss_and_grads(x)\n",
        "     if max_loss is not None and loss_value > max_loss:\n",
        "         break\n",
        "     print('...Loss value at', i, ':', loss_value)\n",
        "     x += step * grad_values\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qqMS0GGb9teh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Finally: the actual DeepDream algorithm\n",
        "### First, define a list of scales (also called octaves) at which to process the images. Each successive scale is larger than the previous one by a factor of 1.4 (it’s 40% larger): you start by processing a small image and then increasingly scale it up\n",
        "### For each successive scale, from the smallest to the largest, you run gradient ascent to maximize the loss you previously defined, at that scale. After each gradient ascent run, you upscale the resulting image by 40%.\n",
        "### To avoid losing a lot of image detail after each successive scale-up (resulting in increasingly blurry or pixelated images), you can use a simple trick: after each scale- up, you’ll reinject the lost details back into the image,\n"
      ]
    },
    {
      "metadata": {
        "id": "_2K1VwQj90xH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Be2tO7hD_DIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "a5183d2a-5ddc-41e6-cc25-d2c9851e66f2"
      },
      "cell_type": "code",
      "source": [
        "step = 0.01 # Gradient ascent step size\n",
        "num_octave = 3 # Number of otaves (# of upscales)\n",
        "octave_scale = 1.4 # Size of upscale (in this case 1.4 or 40%)\n",
        "iterations = 20 # Run gradient ascent for 20 iterations\n",
        "\n",
        "max_loss = 10.  # If the loss grows larger than 10,\n",
        "                # you’ll interrupt the gradient-ascent process to avoid ugly artifacts.\n",
        "\n",
        "base_image_path = 'Brian.png'\n",
        "\n",
        "img = preprocess_image(base_image_path) # Loads the base image into a Numpy array\n",
        "\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "# Prepares a list of shape tuples defining the different scales at which to run gradient ascent\n",
        "for i in range(1, num_octave):\n",
        "    shape = tuple([int(dim / (octave_scale ** i))\n",
        "        for dim in original_shape])\n",
        "    successive_shapes.append(shape)\n",
        "    \n",
        "successive_shapes = successive_shapes[::-1] # Reverses the list of shapes so they’re in increasing order\n",
        "\n",
        "original_img = np.copy(img)\n",
        "shrunk_original_img = resize_img(img, successive_shapes[0]) # Resizes the Numpy array of the image to the smallest scale\n",
        "\n",
        "for shape in successive_shapes:\n",
        "  print('Processing image shape', shape)\n",
        "  img = resize_img(img, shape) # Scales up the image shape \n",
        "  img = gradient_ascent(img, # Runs gradient ascent, altering the dream\n",
        "                        iterations=iterations,\n",
        "                        step=step,\n",
        "                        max_loss=max_loss)\n",
        "  \n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) \n",
        "  same_size_original = resize_img(original_img, shape) # Computes the high-quality version of the original image at this size\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img # The difference between the two is the detail that was lost when scaling up.\n",
        "  \n",
        "  img += lost_detail # Reinjects lost detail into the dream\n",
        "  shrunk_original_img = resize_img(original_img, shape)\n",
        "  save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
        "\n",
        "save_img(img, fname='final_dream.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py:583: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
            "  \"the returned array has changed.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image shape (242, 229)\n",
            "...Loss value at 0 : 1.6487424\n",
            "...Loss value at 1 : 1.9464303\n",
            "...Loss value at 2 : 2.5260575\n",
            "...Loss value at 3 : 3.2020082\n",
            "...Loss value at 4 : 3.809022\n",
            "...Loss value at 5 : 4.4054766\n",
            "...Loss value at 6 : 5.030923\n",
            "...Loss value at 7 : 5.662548\n",
            "...Loss value at 8 : 6.221211\n",
            "...Loss value at 9 : 6.763938\n",
            "...Loss value at 10 : 7.3772407\n",
            "...Loss value at 11 : 7.875053\n",
            "...Loss value at 12 : 8.3797865\n",
            "...Loss value at 13 : 8.85789\n",
            "...Loss value at 14 : 9.308052\n",
            "...Loss value at 15 : 9.775698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image shape (340, 321)\n",
            "...Loss value at 0 : 3.0728703\n",
            "...Loss value at 1 : 4.290121\n",
            "...Loss value at 2 : 5.369831\n",
            "...Loss value at 3 : 6.271934\n",
            "...Loss value at 4 : 7.098414\n",
            "...Loss value at 5 : 7.8373733\n",
            "...Loss value at 6 : 8.530694\n",
            "...Loss value at 7 : 9.15915\n",
            "...Loss value at 8 : 9.773747\n",
            "Processing image shape (476, 450)\n",
            "...Loss value at 0 : 3.1943204\n",
            "...Loss value at 1 : 4.3312073\n",
            "...Loss value at 2 : 5.356767\n",
            "...Loss value at 3 : 6.286502\n",
            "...Loss value at 4 : 7.162728\n",
            "...Loss value at 5 : 7.941783\n",
            "...Loss value at 6 : 8.676771\n",
            "...Loss value at 7 : 9.439405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "htsdtRXvCKhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define some helper functions for working with image\n"
      ]
    },
    {
      "metadata": {
        "id": "v44GfTX6Bi8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkROCFUiBlpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resize_img(img, size):\n",
        "    img = np.copy(img)\n",
        "    factors = (1,\n",
        "               float(size[0]) / img.shape[1],\n",
        "               float(size[1]) / img.shape[2],\n",
        "               1)\n",
        "    return scipy.ndimage.zoom(img, factors, order=1)\n",
        "  \n",
        "def save_img(img, fname):\n",
        "    pil_img = deprocess_image(np.copy(img))\n",
        "    scipy.misc.imsave(fname, pil_img)\n",
        "    \n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path)\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = inception_v3.preprocess_input(img)\n",
        "    return img\n",
        "  \n",
        "def deprocess_image(x):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    else:\n",
        "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
        "    x /= 2.\n",
        "    x += 0.5\n",
        "    x *= 255.\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}