{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nietzsche_WritingStyle_Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "L4yHRQ0457_n"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesPeralta/Machine-Learning-Algorithms/blob/master/Generative%20Models/LSTMs/Nietzsche_WritingStyle_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tICvc0VC3Lnz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Nietzsche Language Model\n",
        "### I will use some of the writings of Nietzsche, the late-nineteenth century German philosopher (translated into English) to train this generatice model. The language model it will learn will be specifically a model of Nietzsche’s writing style and topics of choice, rather than a more generic model of the English language."
      ]
    },
    {
      "metadata": {
        "id": "L4yHRQ0457_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "QmEGxl-H3T3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9d59f80-d326-4af5-a6ce-5f04117c76f9"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cGlhv8IH5Amv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d06033c2-f69d-41cf-e3cc-cac217027c8b"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l2JbM1ZI5QnL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datasets = '/content/drive/My Drive/Datasets/Nietzsche_Writing'\n",
        "os.chdir(datasets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sypj8DYA33gJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "text = open(path).read().lower()\n",
        "print('Corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dv2Nyz_5uJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "947d2da3-ff33-4832-8677-f7d1f2fe99f5"
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "NCvKqHWK5_2X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Vectorizing sequences of characters\n",
        "### I will extract partially overlapping sequences of length maxlen, one-hot encode them, and pack them in a 3D Numpy array x of shape (sequences, maxlen, unique_characters). Simultaneously, i’ll prepare an array y containing the corresponding targets"
      ]
    },
    {
      "metadata": {
        "id": "MWYOxtTl6WQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e6a6dde6-1a23-4928-f553-9f11dcd50db2"
      },
      "cell_type": "code",
      "source": [
        "maxlen = 60 # I will extract sequences of 60 characters\n",
        "step = 3 # Sample a new sequence every three characters\n",
        "sentences = [] # Holds the extracted sequences/samples -> Input\n",
        "next_chars = [] # -> Output\n",
        "\n",
        "# Creates dataset of setences of 60 characters with expected next char\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "   \n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text))) # List of unique characters in the corpus\n",
        "print('Unique characters:', len(chars))\n",
        "char_indices = dict((char, chars.index(char)) for char in chars) # Create a dictionary that maps unique chars to their index in the list \"chars\"\n",
        "            \n",
        "# One-hot encodes the characters into binary arrays\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) # [sentences[Characters in sentence[all possible chars for each char in sentence]]]\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 200278\n",
            "Unique characters: 57\n",
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SqpPeNn4FW8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the network"
      ]
    },
    {
      "metadata": {
        "id": "x5XjARwnFbbN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IApRUl48FryS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "011b9852-bf2b-49a5-de48-71649776b02b"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d3wpaAqrFxxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZzV4cC-F12b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the Language Model and sampling from it\n",
        "Given a trained model and a seed text snippet, you can generate new text by doing the following repeatedly:\n",
        "1. Draw from the model a probability distribution for the next character, given the generated text available so far.\n",
        "2. Reweight the distribution to a certain temperature.\n",
        "3. Sample the next character at random according to the reweighted distribution.\n",
        "4. Add the new character at the end of the available text."
      ]
    },
    {
      "metadata": {
        "id": "trVY0g6tF2Su",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to sample the next character given the model's prediction\n",
        "Code will reweight the original probability distribution coming out of the model and draw a character index from it (the sampling function)"
      ]
    },
    {
      "metadata": {
        "id": "u4LQU2c4Gswj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6_F0NTaeG_43",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text-generation loop\n",
        "Begin generating text using a range of different temperatures after every epoch. This allows you to see how the generated text evolves as the model begins to converge, as well as the impact of temperature in the sampling strategy."
      ]
    },
    {
      "metadata": {
        "id": "vLqP-ZgqHHe-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0fgYpvtHSfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 60):\n",
        "  print('epoch', epoch)\n",
        "  model.fit(x, y, batch_size=128, epochs=1)\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1) \n",
        "  generated_text = text[start_index: start_index + maxlen] \n",
        "  print('--- Generating with seed: \"' + generated_text + '\"')\n",
        "  \n",
        "  for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('------ temperature:', temperature)\n",
        "    sys.stdout.write(generated_text)\n",
        "   \n",
        "  for i in range(400):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "        sampled[0, t, char_indices[char]] = 1.\n",
        "        \n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "    \n",
        "    generated_text += next_char\n",
        "    generated_text = generated_text[1:]\n",
        "    \n",
        "    sys.stdout.write(next_char)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}