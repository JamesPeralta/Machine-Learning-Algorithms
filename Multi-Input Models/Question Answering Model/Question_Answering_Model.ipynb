{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question-Answering-Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "7gobMGsHvmba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question Answering Model\n",
        "### A typical question-answering model has two inputs: a natural-language question and a text snippet (such as a news article) providing information to be used for answering the question. The model must then produce an answer: in the simplest possible setup, this is a one-word answer obtained via a softmax over some predefined vocabulary\n",
        "\n",
        "### Solution: We will set up two independent branches, encoding the text input and the question input as representation vectors; then, concatenate these vectors; and finally, add a softmax classifier on top of the concatenated representations."
      ]
    },
    {
      "metadata": {
        "id": "WVDneAh5vsCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULkaTdRQwQs0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yS5vy-B2wrJh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup reference text branch"
      ]
    },
    {
      "metadata": {
        "id": "EjvAvqkjwWZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ee694505-a80b-4053-b8b6-221deceae185"
      },
      "cell_type": "code",
      "source": [
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "\n",
        "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
        "\n",
        "encoded_text = layers.LSTM(32)(embedded_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m4OlEXKvxEeh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Question branch"
      ]
    },
    {
      "metadata": {
        "id": "DJBLt5UswwzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
        "\n",
        "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
        "\n",
        "encoded_question = layers.LSTM(16)(embedded_question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AnHuTxuxirT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup the concatenation node where both branches meet"
      ]
    },
    {
      "metadata": {
        "id": "K3v_EMgNwdWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8J-9UhazyGpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Add Softmax classifier on top"
      ]
    },
    {
      "metadata": {
        "id": "dosYo9o6yHIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax') (concatenated)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWUFB0gxybtE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile the model"
      ]
    },
    {
      "metadata": {
        "id": "D-kIdPqJyb8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ebf6c39b-2008-4851-8b85-862ab3e8fa25"
      },
      "cell_type": "code",
      "source": [
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           1284224     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 16)           641088      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 48)           0           lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,909,812\n",
            "Trainable params: 2,909,812\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WiY2jpmOyzcN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training: There are two possible APIs\n",
        "#### 1. You can feed the model a list of Numpy arrays as inputs\n",
        "#### 2. Feed it a dictionary that maps input names to Numpy arrays"
      ]
    },
    {
      "metadata": {
        "id": "Znsa75dszL_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GC571pDlzfUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
        "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDp311jVz63Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}